{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/icomp/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Add\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajustando a seed para gerar pesos aleatórios\n",
    "np.random.seed(1)\n",
    "tf.random.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregendo os dados\n",
    "dataset = np.loadtxt('trains.csv', delimiter=',')\n",
    "\n",
    "#separando os dados dos labels\n",
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  4.  2.  1.  9.  3.  4.  2. -1.  5.  1.  1.  3.  1.  9.  1.  3.  2.\n",
      "  -1.  9.  1.  2. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.]\n",
      " [ 4.  3.  2. -1.  1.  1.  1.  2. -1.  2.  1.  4.  2. -1.  4.  2.  2.  0.\n",
      "   0.  0.  0.  0. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  2.  2. -1.  9.  1.  2.  2. -1.  6.  1.  1.  3.  1.  4.  1.  1.  0.\n",
      "   0.  0.  0.  0. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.]\n",
      " [ 5.  2.  2. -1.  2.  1.  1.  2. -1.  3.  1.  1.  2. -1.  8.  1.  4.  2.\n",
      "  -1.  9.  1.  4.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1.]\n",
      " [ 4.  3.  2. -1.  3.  1.  1.  3.  1.  4.  1.  4.  2. -1.  4.  1.  2.  0.\n",
      "   0.  0.  0.  0. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  2.  2.  1.  4.  3.  2.  2. -1.  9.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.]\n",
      " [ 4.  2.  2. -1.  3.  1.  2.  2. -1.  1.  1.  1.  2.  1.  7.  0.  0.  0.\n",
      "   0.  0.  0.  0. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.]\n",
      " [ 3.  2.  3.  1.  4.  1.  4.  2. -1.  1.  1.  2.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 5.  2.  2. -1.  2.  1.  2.  2.  1.  7.  1.  4.  2. -1.  9.  1.  4.  2.\n",
      "  -1.  2.  1.  2.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 3.  1.  2. -1.  1.  1.  4.  2.  1.  9.  2.  4.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "[ 1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construindo nosso modelo para a primeira rede\n",
    "\n",
    "ip = Input(shape=(32,)) #neurônios de entrada\n",
    "x = Dense(9, activation='tanh', kernel_initializer='he_normal')(ip) #Camada escondida\n",
    "out =  Dense(1, activation='tanh')(x) #camada de saída\n",
    "model = Model(outputs=[out],inputs=[ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/icomp/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.9999757 ],\n",
       "       [ 0.99464077],\n",
       "       [ 0.9947883 ],\n",
       "       [ 0.9992981 ],\n",
       "       [ 0.9948395 ],\n",
       "       [-0.99617064],\n",
       "       [-0.9999245 ],\n",
       "       [-0.99602324],\n",
       "       [-0.99192154],\n",
       "       [-0.9999997 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.3, momentum=0.4, nesterov=False)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "model.fit(X,y, epochs=10000, batch_size=9,validation_split=0.1, verbose=0)\n",
    "model.predict(X) #predizendo os exemplos usados no treino..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparação ppara fazer leave one out cross-validation\n",
    "lx = []\n",
    "ly = []\n",
    "X2 = [list(x) for x in X]\n",
    "y2 = [float(x) for x in y]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(X2)):\n",
    "    lx.append(X2[:i]+[X2[k] for k in range(len(X2)) if i < k]+[X2[i]])\n",
    "    ly.append(y2[:i]+[y2[k] for k in range(len(y2)) if i < k]+[y2[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira rede\n",
    "\n",
    "Feita com KBANN (pesos aleatórios) e validada com leave one out crossvalidation.\n",
    "\n",
    "Funções de ativação: tanh\n",
    "\n",
    "Accuracy = 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(lx)):\n",
    "    ip = Input(shape=(32,)) #neurônios de entrada\n",
    "    x = Dense(9, activation='tanh', kernel_initializer='he_normal')(ip) #Camada escondida\n",
    "    out =  Dense(1, activation='tanh')(x) #camada de saída\n",
    "    model = Model(outputs=[out],inputs=[ip])\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.3, momentum=0.4, nesterov=False)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "    model.fit(np.array(lx[i])[:-1:], np.array(ly[i])[:-1:], epochs=10000, batch_size=9, verbose=0)\n",
    "    predictions.append(model.predict(np.array(lx[i])[-1::])[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295803 (expected: 1.0 )\n",
      "0.598682 (expected: 1.0 )\n",
      "-0.99264264 (expected: 1.0 )\n",
      "0.964253 (expected: 1.0 )\n",
      "0.0065902695 (expected: 1.0 )\n",
      "0.7987824 (expected: -1.0 )\n",
      "0.66667014 (expected: -1.0 )\n",
      "0.99148434 (expected: -1.0 )\n",
      "-0.32639512 (expected: -1.0 )\n",
      "-0.9991104 (expected: -1.0 )\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(predictions)):\n",
    "    print(predictions[x], \"(expected:\",y[x],\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda rede\n",
    "\n",
    "Feita com proposicionalização e validada com leave one out crossvalidation.\n",
    "\n",
    "Os pesos representam a influência de um determinado neurônio de entrada na preposição que gerou aquele neurônio.\n",
    "\n",
    "O peso 3.5 e os bias foram calculados segundo [1].\n",
    "\n",
    "Funções de ativação: sigmoid para a camada escondida e tanh para a saída.\n",
    "\n",
    "Accuracy: 60%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1] Garcez, A. and Zaverucha, G. (1999). The connectionist inductive learning and\n",
    "    logic programming system. Applied Intelligence Journal, 11(1), pp. 59-77. doi:\n",
    "    10.1023/A:1008328630915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5], [3.5], [3.5], [3.5], [3.5], [-3.5], [-3.5], [-3.5], [-3.5], [-3.5]]\n"
     ]
    }
   ],
   "source": [
    "weights = [[1,0,1,1,1,1,1,1,-1,1,1,1,1,1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "           [1,0,1,-1,1,1,1,1,-1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,-1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,-1,1,1,1,1,-1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,-1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,1,1,1,1,1,-1,1,1,1,1,-1,1,1,1,0,0,0,0,0,0,0,0,0,0],\\\n",
    "           [1,0,1,-1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "\n",
    "weights_out = [[1],[1],[1],[1],[1],[-1],[-1],[-1],[-1],[-1]]\n",
    "\n",
    "weights = [[k*(3.5) for k in i] for i in weights]\n",
    "weights_out = [[k*(3.5) for k in i] for i in weights_out]\n",
    "\n",
    "\n",
    "bias = [[1.32],\\\n",
    "       [0.99],\\\n",
    "       [0.99],\\\n",
    "       [1.32],\\\n",
    "       [0.99],\\\n",
    "       [0.66],\\\n",
    "       [0.99],\\\n",
    "       [0.66],\\\n",
    "       [1.32],\\\n",
    "       [0.66]]\n",
    "\n",
    "bias_out = [[-0.96]]\n",
    "\n",
    "\n",
    "print(weights_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = []\n",
    "lw_out = []\n",
    "lb = []\n",
    "for i in range(len(weights)):\n",
    "    lw.append(weights[:i:]+[weights[k] for k in range(len(weights)) if k > i]+[weights[i]])\n",
    "    lw_out.append(weights_out[:i:]+[weights_out[k] for k in range(len(weights_out)) if k > i]+[weights_out[i]])\n",
    "    lb.append(bias[:i:]+[bias[k] for k in range(len(bias)) if k > i]+[bias[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lw_init(shape, dtype=None):\n",
    "    global i,lw\n",
    "    #print(np.array(lw[i][:-1:], dtype=dtype).T)\n",
    "    return np.array(lw[i][:-1:], dtype=dtype).T\n",
    "\n",
    "def lb_init(shape, dtype=None):\n",
    "    global i,lb\n",
    "    #print(np.array(lb[i][:-1:], dtype=dtype).T[0])\n",
    "    return np.array(lb[i][:-1:], dtype=dtype).T[0]\n",
    "\n",
    "def lw_out_init(shape, dtype=None):\n",
    "    global i,lw_out\n",
    "    #print(np.array(lw_out[i][:-1:], dtype=dtype))\n",
    "    return np.array(lw_out[i][:-1:], dtype=dtype)\n",
    "\n",
    "def bias_out_init(shape, dtype=None):\n",
    "    global i,lb\n",
    "    #print(np.array(bias_out[0], dtype=dtype))\n",
    "    return np.array(bias_out[0], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "global i\n",
    "for i in range(len(lx)):\n",
    "    ip = Input(shape=(32,)) #neurônios de entrada\n",
    "    x = Dense(9, activation='sigmoid',\\\n",
    "             kernel_initializer=lw_init,\\\n",
    "             bias_initializer=lb_init)(ip) #Camada escondida\n",
    "    \n",
    "    out =  Dense(1, activation='tanh',\\\n",
    "                 kernel_initializer=lw_out_init,\\\n",
    "                 bias_initializer=bias_out_init)(x) #camada de saída\n",
    "    \n",
    "    model = Model(outputs=[out],inputs=[ip])\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.3, momentum=0.4, nesterov=False)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "    model.fit(np.array(lx[i])[:-1:], np.array(ly[i])[:-1:], epochs=10000, batch_size=1,verbose=0)\n",
    "    predictions.append(model.predict(np.array(lx[i])[-1::])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 (expected: 1.0 )\n",
      "1.0 (expected: 1.0 )\n",
      "-1.0 (expected: 1.0 )\n",
      "-1.0 (expected: 1.0 )\n",
      "1.0 (expected: 1.0 )\n",
      "1.0 (expected: -1.0 )\n",
      "1.0 (expected: -1.0 )\n",
      "1.0 (expected: -1.0 )\n",
      "-1.0 (expected: -1.0 )\n",
      "1.0 (expected: -1.0 )\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(predictions)):\n",
    "    print(predictions[x], \"(expected:\",y[x],\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.3471217],\n",
       "        [ 2.3471217],\n",
       "        [ 2.3471217],\n",
       "        [ 2.3471217],\n",
       "        [ 2.3471217],\n",
       "        [-4.6528544],\n",
       "        [-4.6528544],\n",
       "        [-4.6528544],\n",
       "        [-4.6528544],\n",
       "        [-4.6528544]], dtype=float32), array([-2.112987], dtype=float32)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-113-e523bdf51e29>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-113-e523bdf51e29>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install pydot --user\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install pydot --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-be55c87f0967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "#plot\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo regras da segunda rede\n",
    "\n",
    "Primeiramente treinamos ela novamente, agora com todos os 10 exemplos. Em seguida observamos os pesos encontrados após o processo de aprendizagem para descobrir qual a influência das cláusulas no resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x7ff0b7a39b00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/icomp/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-461ef1dcccf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lw_init(shape, dtype=None):\n",
    "    global weights\n",
    "    return np.array(weights, dtype=dtype).T\n",
    "\n",
    "def lb_init(shape, dtype=None):\n",
    "    global bias\n",
    "    return np.array(bias, dtype=dtype).T[0]\n",
    "\n",
    "def lw_out_init(shape, dtype=None):\n",
    "    global weights_out\n",
    "    return np.array(weights_out, dtype=dtype)\n",
    "\n",
    "def bias_out_init(shape, dtype=None):\n",
    "    global bias_out\n",
    "    return np.array(bias_out[0], dtype=dtype)\n",
    "\n",
    "ip = Input(shape=(32,)) #neurônios de entrada\n",
    "x = Dense(9, activation='tanh',\\\n",
    "             kernel_initializer=lw_init,\\\n",
    "             bias_initializer=lb_init)(ip) #Camada escondida\n",
    "    \n",
    "out =  Dense(1, activation='tanh',\\\n",
    "                 kernel_initializer=lw_out_init,\\\n",
    "                 bias_initializer=bias_out_init)(x) #camada de saída\n",
    "    \n",
    "model = Model(outputs=[out],inputs=[ip])\n",
    "opt = keras.optimizers.SGD(learning_rate=0.3, momentum=0.4, nesterov=False)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "model.fit(X, y, epochs=10000, batch_size=1,verbose=0)\n",
    "predictions= [i for i in model.predict(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] (expected: 1.0 )\n",
      "[1.] (expected: 1.0 )\n",
      "[1.] (expected: 1.0 )\n",
      "[1.] (expected: 1.0 )\n",
      "[1.] (expected: 1.0 )\n",
      "[1.] (expected: -1.0 )\n",
      "[1.] (expected: -1.0 )\n",
      "[1.] (expected: -1.0 )\n",
      "[1.] (expected: -1.0 )\n",
      "[1.] (expected: -1.0 )\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(predictions)):\n",
    "    print(predictions[x], \"(expected:\",y[x],\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
